{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kimbail The Data Warehouse Tool kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of Data Warehousing and Business Intelligence\n",
    "- a data warehouse must be simple to understand its labels and structure. obvious to the business user, mimicking the business terminology.  \n",
    "- accessible and easy to interact with, and provide numerous way to display data.\n",
    "- provide fast query performance.\n",
    "- its data quality must be insured and only deployed when it is validated.\n",
    "- its data must be consistent from all sources.\n",
    "- the warehouse should handle changes, new data, new application, and new business requirements without affecting the data warehouse operations.\n",
    "- fast to deliver raw data to operation business users\n",
    "- the warehouse must control access to the data to protect the business data\n",
    "- the data warehouse must be accepted by the business users (if the solution doesn't improve the business user workflow it wont be used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DW/BI Managers Responsibilities\n",
    "\n",
    "- Understand the business users:\n",
    "    - Understand their job responsibilities, goals, and objectives.\n",
    "    - Determine the decisions that the business users want to make with the\n",
    "    help of the DW/BI system.\n",
    "    - Identify the “best” users who make effective, high-impact decisions.\n",
    "    - Find potential new users and make them aware of the DW/BI system’s\n",
    "    capabilities.\n",
    "\n",
    "</b>\n",
    "\n",
    "- Deliver high-quality, relevant, and accessible information and analytics to\n",
    "the business users:\n",
    "    - Choose the most robust, actionable data to present in the DW/BI system,\n",
    "    carefully selected from the vast universe of possible data sources\n",
    "    in your organization.\n",
    "    - Make the user interfaces and applications simple and template-driven,\n",
    "    explicitly matched to the users’ cognitive processing profiles.\n",
    "    - Make sure the data is accurate and can be trusted, labeling it consistently\n",
    "    across the enterprise.\n",
    "    - Continuously monitor the accuracy of the data and analyses.\n",
    "    - Adapt to changing user profiles, requirements, and business priorities,\n",
    "    along with the availability of new data sources.\n",
    "\n",
    "</b>\n",
    "\n",
    "- Sustain the DW/BI environment:\n",
    "    - Take a portion of the credit for the business decisions made using the\n",
    "    DW/BI system, and use these successes to justify staffing and ongoing\n",
    "    expenditures.\n",
    "    - Update the DW/BI system on a regular basis.\n",
    "    - Maintain the business users’ trust.\n",
    "    - Keep the business users, executive sponsors, and IT management\n",
    "    happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional modelling\n",
    "\n",
    "dimensional addresses __delivering data that is understandable to business users__ and __delivering fast query performance__ data warehousing goals.\n",
    "\n",
    "3NF models:\n",
    "3NF models are used in operational databases and are beneficial since the normalized tables eliminate redundancy and insert update data in one place. however, normalized models are to complicated for analytical queries, users cant understand or navigate complex normalized models, and databases process complex joins slowly.\n",
    "\n",
    "OLAP cubes:\n",
    "- OLAP cubes (dimensional database) preform queries faster than the star schema (Relational database) due to indexing and preloaded summery tables, however, it can handle larger datasets.\n",
    "- its difficult to port bi applications between different vendors since the data structure is not standardized between vendors\n",
    "- unlike RDMS OLAP cubes have more capabilities since its not constrained by SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Tables for Measurements\n",
    "\n",
    "for a retail store selling products where each row in a fact table represent a measurement event(transaction):\n",
    "- all measurement should be the same level of detail such as row per product, ensuring measurements aren't duplicated.\n",
    "- the idea that a measurement event has a one to one relationship to a single row in the corresponding fact table is the bedrock of \n",
    "- The most useful facts are numeric and additive, such as dollar sales amount.the most useful thing to do with so many rows is to add them up You will see that facts are sometimes semi-additive or even non-additive.\n",
    "    - Semi-additive facts, such as account balances, cannot be summed across the time dimension. \n",
    "    - Non-additive facts, such as unit prices, can never be added. You are forced to use counts and averages or are reduced to printing out the fact rows one at a time, an impractical exercise with a billion-row fact table.\n",
    "- You should not store redundant textual information in fact tables. Unless the text is unique for every row in the fact table (its rare to use textual data in the fact table, especially since it takes more space and is harder to analyze)\n",
    "- the primary key of a fact table is usually a composite key made of a subset of the foreign keys\n",
    "- its important not to fill the fact table with zeros for no activity, this could overwhelm the fact table\n",
    "- example fact table:\n",
    "\n",
    "|Retail Sales Facts|\n",
    "|------------------|\n",
    "|Date Key (FK)|\n",
    "|Product Key (FK)|\n",
    "|Store Key (FK)|\n",
    "|Promotion Key (FK)|\n",
    "|Customer Key (FK)|\n",
    "|Clerk Key (FK)|\n",
    "|Transaction #|\n",
    "|Sales Dollars|\n",
    "|Sales Units|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional tables\n",
    "- They describe the “who, what, where, when, how, and why” associated with the event.\n",
    "- It is not uncommon for a dimension table to have 50 to 100 attributes; however, they tend to have fewer rows than the fact table\n",
    "- Dimension attributes serve as the primary source of query constraints, groupings,and report labels.\n",
    "- Attributes should consist of real words rather than codes. (unless having legitimate business significance)\n",
    "- When sorting operational source data, it is sometimes unclear whether a numeric data element is a fact or dimension attribute. You often make the decision by asking whether the column is a measurement that takes on lots of values and participates in calculations (making it a fact) or is a discretely valued description that is more or less constant and participates in constraints and row labels (making it a dimensional attribute). For example, the standard cost for a product seems like a constant attribute of the product but may be changed so often that you decide it is more like a measured fact. Occasionally, you can’t be certain of the classification; it is possible to model the data element either way (or both ways) as a matter of the designer’s prerogative.\n",
    "- You should almost always trade off dimension table space for simplicity and accessibility. (avoid normalizing redundant hierarchies like Category> brand> product into lookup tables and prioritize simplicity and performance over storage efficiency  )\n",
    "- example dimension table:\n",
    "\n",
    "|Product Dimension|\n",
    "|-----------------|\n",
    "|Product Key (PK)|\n",
    "|SKU Number (Natural Key)|\n",
    "|Product Description|\n",
    "|Brand Name|\n",
    "|Category Name|\n",
    "|Department Name|\n",
    "|Package Type|\n",
    "|Package Size|\n",
    "|Abrasive Indicator|\n",
    "|Weight|\n",
    "|Weight Unit of Measure|\n",
    "|Storage Type|\n",
    "|Shelf Life Type|\n",
    "|Shelf Width|\n",
    "|Shelf Height|\n",
    "|Shelf Depth|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Extract, Transformation, and Load System\n",
    "\n",
    "- Extracting means reading and understanding the source data and copying the data needed into the ETL system for further manipulation.\n",
    "- there are numerous potential transformations, such as cleansing the data (correcting misspellings, resolving domain conflicts, dealing with missing elements, or parsing into standard formats), combining data from multiple sources, and de-duplicating data.\n",
    "    - these activities can be architected to create diagnostic metadata, eventually leading to business process re-engineering to improve data quality in the source systems over time.\n",
    "- The final step of the ETL process is the physical structuring and loading of data into the presentation area’s target dimensional models. Because the primary mission of the ETL system is to hand off the dimension and fact tables in the delivery step, these subsystems are critical. Many of these defined subsystems focus on dimension table processing, such as surrogate key assignments, code lookups to provide appropriate descriptions, splitting, or combining columns to present the appropriate data values, or joining underlying third normal form table structures into flattened de-normalized dimensions. In contrast, fact tables are typically large and time consuming to load, but preparing them for the presentation area is typically straightforward. When the dimension and fact tables in a dimensional model have been updated, indexed, supplied with appropriate aggregates, and further quality assured, the business community is notified that the new data has been published.\n",
    "- The ETL system is typically dominated by the simple activities of sorting and sequential processing. In many cases, the ETL system is not based on relational technology but instead may rely on a system of flat files. (it might be pointless to build a 3NF database just before de-normalizing it for the warehouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentation Area to Support Business Intelligence\n",
    "\n",
    "in our opinion\n",
    "- it is completely unacceptable to store only summary data in dimensional models, while the atomic data is locked up in normalized models. BI users may be interested in last week’s orders for products of a given size (or flavor, package type, or manufacturer) for customers who first purchased within 6 month for example \n",
    "- The presentation data area should be structured around business process measurement events. This approach naturally aligns with the operational source data capture systems. Dimensional models should correspond to physical data capture events; they should not be designed to deliver the report-of-the-day.\n",
    "- Data in the queryable presentation area of the DW/BI system must be dimensional, atomic (complemented by performance-enhancing aggregates), business process-centric, and adhere to the enterprise data warehouse bus architecture. The data must not be structured according to individual departments’ interpretation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
